# DirScan
DirScan是一款探测网站路径的工具,批量扫描网站的路径(目录或文件名或Api)，快速发现目标薄弱点

#### Usage
--------------------------------------------------------------------------------
推荐使用python3.8以上版本
```
python3 dirscan.py --target [source urls file] --dirs [dir dict file] --filenames [filename dict file]
```


#### 主要功能：
--------------------------------------------------------------------------------
- 实现异步协程(asyncio + httpx)快速扫描目标
- 主要结合响应码和其他辅助因素判断网站路径存活概率
- 对扫描过程中发现的可用路径，继续拼接字典扫描
- 对命中路径添加到列表，Counter 模块进行计数，计数入库sqlite
- 对响应大量200或403状态码的网站，取消继续扫描
- 扫描结果保存CSV格式，分为html返回（url  |  status code | title | 响应长度） 和 json返回 （url  |  status code | JSON | 响应长度），二者皆无返回None


#### 多因素分析常见响应码: 判断网站路径是否有潜在利用价值
--------------------------------------------------------------------------------
- 200相关
> 需要结合页面关键字、响应headers content-length、页面相似度等判断网站状态

- 30x
> 允许请求跳转，allow_redirects=True

- 403相关
如果网站某路径扫描返回403？此时访问该路径url+随机字符：
> 1. 如果返回403，则有一定概率是除了该路径下的某些资源可能访问外，访问其他资源都返回403，此时探测成功率低
> 2. 如果返回404，则有一定概率是，网站默认首页文件配置错误，此时探测成功率相比上面高一些

- 404相关
如果网站某路径扫描返回404？此时访问该路径url+随机字符：
> 如果返回404，此时可能根目录下除了某些资源可访问外，其他都返回404，因为DirScan中会有大量404响应，此时继续探测价值低，可以放弃

- 50x
> 重试处理，可能网站某段时间服务端异常，需要多次请求才能判断


#### 扫描结果分类保存CSV文件：
--------------------------------------------------------------------------------
- 应该正常网站： 响应码 20x  、30x为主
- 潜在探测价值网站：403为主
- 无探测价值网站，404，50x为主

#### 后续计划
--------------------------------------------------------------------------------
- 单个网站扫描频率控制或者配置代理，防止封IP
- 目标路径数量过大时，进行大任务拆分

